{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a4dca3-d73a-4013-a45e-42181dcc5df6",
   "metadata": {},
   "source": [
    "## Assignment 3 - Decision Tree\n",
    "\n",
    "### Objective:\n",
    "\n",
    "To classify breast cancer patients as \"Alive\" or \"Dead\" based on their characteristics using a decision tree model.\n",
    "\n",
    "### Dataset:\n",
    "\n",
    "This dataset comprises information on female breast cancer patients diagnosed between 2006 and 2010 with infiltrating duct and lobular carcinoma of the breast. The data was obtained from the SEER Program's November 2017 update.\n",
    "\n",
    "**Input Variables:**\n",
    "\n",
    "- **Age:** Age of the patient\n",
    "- **Race:** Patient's race\n",
    "- **Marital Status:** Marital status of the patient\n",
    "- **T Stage:** Adjusted AJCC 6th T stage classification for the tumor\n",
    "- **N Stage:** Adjusted AJCC 6th N stage classification for regional lymph nodes\n",
    "- **6th Stage:** Breast cancer adjusted AJCC 6th stage classification\n",
    "- **Differentiate:** The degree of differentiation of the tumor\n",
    "- **Grade:** The grade of the tumor, indicating its aggressiveness\n",
    "- **A Stage:** Regional or Distant metastasis\n",
    "- **Tumor Size:** Exact size of the tumor in millimeters\n",
    "- **Estrogen Status:** Status of estrogen receptor in the tumor\n",
    "- **Progesterone Status:** Status of progesterone receptor in the tumor\n",
    "- **Regional Node Examined:** Number of regional lymph nodes examined\n",
    "- **Regional Node Positive:** Number of regional lymph nodes positive for cancer\n",
    "- **Survival Months:** Number of months the patient survived after diagnosis\n",
    "\n",
    "### Output Variable:\n",
    "**Status:** Dead/Alive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9850364-41f7-44f4-9358-777b7a62b950",
   "metadata": {},
   "source": [
    "## Importing libraries and Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89b455fe-91db-48bb-a630-2d25b563f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032142ab",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09c35c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>6th Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>Grade</th>\n",
       "      <th>A Stage</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Reginol Node Positive</th>\n",
       "      <th>Survival Months</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N2</td>\n",
       "      <td>IIIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>35</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T3</td>\n",
       "      <td>N3</td>\n",
       "      <td>IIIC</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>63</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>41</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   Race Marital Status T Stage N Stage 6th Stage  \\\n",
       "0   68  White        Married      T1      N1       IIA   \n",
       "1   50  White        Married      T2      N2      IIIA   \n",
       "2   58  White       Divorced      T3      N3      IIIC   \n",
       "3   58  White        Married      T1      N1       IIA   \n",
       "4   47  White        Married      T2      N1       IIB   \n",
       "\n",
       "               differentiate Grade   A Stage  Tumor Size Estrogen Status  \\\n",
       "0      Poorly differentiated     3  Regional           4        Positive   \n",
       "1  Moderately differentiated     2  Regional          35        Positive   \n",
       "2  Moderately differentiated     2  Regional          63        Positive   \n",
       "3      Poorly differentiated     3  Regional          18        Positive   \n",
       "4      Poorly differentiated     3  Regional          41        Positive   \n",
       "\n",
       "  Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
       "0            Positive                      24                      1   \n",
       "1            Positive                      14                      5   \n",
       "2            Positive                      14                      7   \n",
       "3            Positive                       2                      1   \n",
       "4            Positive                       3                      1   \n",
       "\n",
       "   Survival Months Status  \n",
       "0               60  Alive  \n",
       "1               62  Alive  \n",
       "2               75  Alive  \n",
       "3               84  Alive  \n",
       "4               50  Alive  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('Breast_Cancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135b5c7-e14f-4737-84e5-9af2a731c36c",
   "metadata": {},
   "source": [
    "## Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da031b0e-d777-4848-965d-e882f38b5669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3219, 16), (805, 16))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state = 1)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151d4c6-d2b3-4e7e-885f-722c37fc44f7",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "\n",
    "### Algorithm:\n",
    "- Start with all examples at the root node\n",
    "- Calculate gini impurity for splitting on all possible features and select the one with the lowest possible value\n",
    "- Split the data according to the selected feature\n",
    "- Repeat recursively until stopping criteria met.\n",
    "\n",
    "### Gini Impurity\n",
    "It is calculated for any feature as follows:\n",
    "$$Gini\\space Impurity\\space (G) = 1 - \\sum\\limits_{}^{} p_{i}^2$$\n",
    "\n",
    "Where \\( $ p_i $ \\) is the probability of an element being classified for a particular class.\n",
    "\n",
    "### Gini Impurity of Node Split\n",
    "\n",
    "**The Gini Impurity for a node split is calculated using the following formula:**\n",
    "\n",
    "$$G_{\\text{split}} = \\frac{N_{\\text{left}}}{N} G_{\\text{left}} + \\frac{N_{\\text{right}}}{N} G_{\\text{right}}$$\n",
    "\n",
    "**Where:**\n",
    "- \\($ G_{\\text{split}} $\\) is the Gini Impurity of the split.\n",
    "- \\($ N_{\\text{left}} $\\) is the number of samples in the left child node.\n",
    "- \\($ N_{\\text{right}} $\\) is the number of samples in the right child node.\n",
    "- \\($ N $ \\) is the total number of samples (i.e., \\($ N = N_{\\text{left}} + N_{\\text{right}} $\\)).\n",
    "- \\($ G_{\\text{left}} $\\) is the Gini Impurity of the left child node.\n",
    "- \\($ G_{\\text{right}} $\\) is the Gini Impurity of the right child node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2e8a0b-f5f0-4df2-9f89-805d64801299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a node class to represent the decision tree structure\n",
    "class DTNode:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.children = {}\n",
    "\n",
    "# Define the custom decision tree classifier\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.root = DTNode(None)\n",
    "        self.tree_depth = -1\n",
    "\n",
    "    # Calculate potential splits for continuous features\n",
    "    def find_splits(self, data, feature_idx, feature_name):\n",
    "        continuous_features =  ['Age', 'Tumor Size', 'Reginol Node Positive', 'Regional Node Examined', 'Survival Months']\n",
    "\n",
    "        if feature_name not in continuous_features:\n",
    "            return []\n",
    "\n",
    "        values_labels = data[:, [feature_idx, -1]]\n",
    "        sorted_data = values_labels[values_labels[:, 0].argsort()]\n",
    "        split_points = []\n",
    "\n",
    "        for i in range(len(sorted_data) - 1):\n",
    "            current_value = sorted_data[i][0]\n",
    "            next_value = sorted_data[i + 1][0]\n",
    "\n",
    "            if current_value != next_value:\n",
    "                midpoint = (current_value + next_value) / 2\n",
    "                split_points.append(midpoint)\n",
    "\n",
    "        return split_points\n",
    "\n",
    "    # Calculate the Gini impurity for a given dataset\n",
    "    def compute_gini(self, data):\n",
    "        labels = data[:, -1]\n",
    "        _, label_counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = label_counts / label_counts.sum()\n",
    "        gini_score = 1 - np.sum(np.square(probabilities))\n",
    "        return gini_score\n",
    "\n",
    "    # Determine the most common class for a given dataset (for leaf nodes)\n",
    "    def majority_class(self, data):\n",
    "        labels = data.iloc[:, -1]\n",
    "        classes, counts = np.unique(labels, return_counts=True)\n",
    "        return classes[np.argmax(counts)]\n",
    "\n",
    "    # Create a leaf node when no further split is possible\n",
    "    def create_leaf_node(self, data):\n",
    "        classification = self.majority_class(data)\n",
    "        gini = self.compute_gini(data.values)\n",
    "\n",
    "        node_data = {\n",
    "            \"Node Type\": \"Leaf\",\n",
    "            \"Class\": classification,\n",
    "            \"Gini\": gini,\n",
    "            \"Sample Count\": data.shape[0]\n",
    "        }\n",
    "        return DTNode(node_data)\n",
    "\n",
    "    # Recursive function to build the decision tree\n",
    "    def build_tree(self, data, max_depth, available_features, current_depth):\n",
    "        # Base case: all samples have the same class\n",
    "        if len(np.unique(data.iloc[:, -1])) == 1:\n",
    "            return self.create_leaf_node(data)\n",
    "\n",
    "        # Base case: reached max depth or no more features to split\n",
    "        if current_depth >= max_depth or len(available_features) == 0:\n",
    "            return self.create_leaf_node(data)\n",
    "\n",
    "        best_split = {\"Feature\": \"\", \"Attribute\": \"\", \"Split_Point\": None, \"Best_Gini\": float('inf')}\n",
    "\n",
    "        for feature in available_features:\n",
    "            col_idx = data.columns.get_loc(feature)\n",
    "            potential_splits = self.find_splits(data.values, col_idx, feature)\n",
    "\n",
    "            # For continuous features, find the optimal split\n",
    "            if potential_splits:\n",
    "                for split_value in potential_splits:\n",
    "                    left_subset = data[data[feature] <= split_value]\n",
    "                    right_subset = data[data[feature] > split_value]\n",
    "                    gini_weighted = (\n",
    "                        len(left_subset) * self.compute_gini(left_subset.values) +\n",
    "                        len(right_subset) * self.compute_gini(right_subset.values)\n",
    "                    ) / len(data)\n",
    "\n",
    "                    if gini_weighted < best_split[\"Best_Gini\"]:\n",
    "                        best_split.update({\n",
    "                            \"Feature\": feature,\n",
    "                            \"Attribute\": col_idx,\n",
    "                            \"Split_Point\": split_value,\n",
    "                            \"Best_Gini\": gini_weighted\n",
    "                        })\n",
    "            # For categorical features, evaluate each unique value\n",
    "            else:\n",
    "                unique_vals = np.unique(data.iloc[:, col_idx])\n",
    "                gini_accumulation = 0\n",
    "\n",
    "                for val in unique_vals:\n",
    "                    subset = data[data[feature] == val]\n",
    "                    gini_val = self.compute_gini(subset.values)\n",
    "                    gini_accumulation += (len(subset) / len(data)) * gini_val\n",
    "\n",
    "                if gini_accumulation < best_split[\"Best_Gini\"]:\n",
    "                    best_split.update({\n",
    "                        \"Feature\": feature,\n",
    "                        \"Attribute\": col_idx,\n",
    "                        \"Split_Point\": unique_vals,\n",
    "                        \"Best_Gini\": gini_accumulation\n",
    "                    })\n",
    "\n",
    "        # Create a leaf if no valid split is found\n",
    "        if best_split[\"Feature\"] == \"\":\n",
    "            return self.create_leaf_node(data)\n",
    "\n",
    "        # Store node information and split recursively\n",
    "        node_data = {\n",
    "            \"Feature\": best_split[\"Feature\"],\n",
    "            \"Gini\": best_split[\"Best_Gini\"],\n",
    "            \"Samples\": data.shape[0],\n",
    "            \"Best_Split\": best_split[\"Split_Point\"]\n",
    "        }\n",
    "        node = DTNode(node_data)\n",
    "\n",
    "        # Recursive splitting for continuous vs categorical features\n",
    "        if best_split[\"Feature\"] in  ['Age', 'Tumor Size', 'Reginol Node Positive', 'Regional Node Examined', 'Survival Months']:\n",
    "            node.children[\"left\"] = self.build_tree(data[data[best_split[\"Feature\"]] <= best_split[\"Split_Point\"]],\n",
    "                                                    max_depth, available_features, current_depth + 1)\n",
    "            node.children[\"right\"] = self.build_tree(data[data[best_split[\"Feature\"]] > best_split[\"Split_Point\"]],\n",
    "                                                     max_depth, available_features, current_depth + 1)\n",
    "        else:\n",
    "            for val in best_split[\"Split_Point\"]:\n",
    "                subset = data[data[best_split[\"Feature\"]] == val]\n",
    "                node.children[val] = self.build_tree(subset, max_depth, available_features, current_depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    # Function to initiate model fitting\n",
    "    def fit(self, data, max_depth=10):\n",
    "        features = data.columns.tolist()[:-1]\n",
    "        self.feature_names = np.array(features)\n",
    "        self.root = self.build_tree(data, max_depth, features, 0)\n",
    "\n",
    "   \n",
    "    # Predict the class for a single data point\n",
    "    def predict_single(self, data_point):\n",
    "        node = self.root\n",
    "        while \"Class\" not in node.value.keys():\n",
    "            node_data = node.value\n",
    "            if node_data[\"Feature\"] in  ['Age', 'Tumor Size', 'Reginol Node Positive', 'Regional Node Examined', 'Survival Months']:\n",
    "                if data_point[np.argwhere(self.feature_names == node_data[\"Feature\"]).squeeze()] <= node_data[\"Best_Split\"]:\n",
    "                    node = node.children[\"left\"]\n",
    "                else:\n",
    "                    node = node.children[\"right\"]\n",
    "            else:\n",
    "                feature_val = data_point[np.argwhere(self.feature_names == node_data[\"Feature\"]).squeeze()]\n",
    "                node = node.children.get(feature_val, None)\n",
    "                if node is None:\n",
    "                    return -1\n",
    "\n",
    "        return node.value[\"Class\"]\n",
    "\n",
    "    # Predict the class for multiple data points\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_single(row) for row in X])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c52bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for 1 : 91.80%\n",
      "Test Accuracy for 2 : 91.80%\n",
      "Test Accuracy for 3 : 91.55%\n",
      "Test Accuracy for 4 : 91.68%\n",
      "Test Accuracy for 5 : 89.69%\n",
      "Test Accuracy for 6 : 88.94%\n",
      "Test Accuracy for 7 : 88.07%\n",
      "Test Accuracy for 8 : 86.21%\n",
      "Test Accuracy for 9 : 85.34%\n",
      "Test Accuracy for 10 : 84.35%\n",
      "Test Accuracy for 11 : 84.35%\n",
      "Test Accuracy for 12 : 84.22%\n",
      "Test Accuracy for 13 : 83.73%\n",
      "Test Accuracy for 14 : 83.60%\n",
      "Test Accuracy for 15 : 83.35%\n",
      "Test Accuracy for 16 : 83.35%\n",
      "Test Accuracy for 17 : 83.35%\n",
      "Test Accuracy for 18 : 83.35%\n",
      "Test Accuracy for 19 : 83.35%\n",
      "Test Accuracy for 20 : 83.35%\n",
      "Maximum Accuracy is : 0.9180124223602485 for epoch : 1\n"
     ]
    }
   ],
   "source": [
    "def epoch_fit():\n",
    "    model = DecisionTree()\n",
    "    best = 0\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(1,21):\n",
    "        model.fit(train_df,epoch)\n",
    "\n",
    "        X_test = test_df.values[:,:-1]\n",
    "        Y_test = test_df.values[:,-1]\n",
    "\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        if(best_accuracy<accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best = epoch\n",
    "        print(f\"Test Accuracy for {epoch} : {accuracy * 100:.2f}%\")\n",
    "\n",
    "    \n",
    "    print(f\"Maximum Accuracy is : {best_accuracy} for epoch : {best}\")\n",
    "\n",
    "epoch_fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
