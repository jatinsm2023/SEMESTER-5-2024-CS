{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7d3d4b7-e7ad-4503-96d2-3d3b10b1f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc2dbff-08dd-4dd7-8cbc-4e84209c18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.3</td>\n",
       "      <td>504000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>9.14</td>\n",
       "      <td>17.8</td>\n",
       "      <td>453600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.8</td>\n",
       "      <td>728700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.7</td>\n",
       "      <td>701400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.7</td>\n",
       "      <td>760200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RM  LSTAT  PTRATIO      MEDV\n",
       "0  6.575   4.98     15.3  504000.0\n",
       "1  6.421   9.14     17.8  453600.0\n",
       "2  7.185   4.03     17.8  728700.0\n",
       "3  6.998   2.94     18.7  701400.0\n",
       "4  7.147   5.33     18.7  760200.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45a31b5-d88a-4d03-aa45-95efb3bcb55a",
   "metadata": {},
   "source": [
    "\n",
    "### Activation Function\n",
    "We use the **sigmoid activation function**, defined as: \n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b2b01ee-22d8-4cfc-88ac-4ea6711ff001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "\n",
    "    def __init__(self, input_layer_size = 2, hidden_layer_size = 2, output_layer_size = 2, lr = 0.5, epoches = 1000):\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.output_layer_size = output_layer_size\n",
    "        self.lr = lr\n",
    "        self.number_of_epoches = epoches\n",
    "\n",
    "        #initialize the weights\n",
    "        #1. by random numbers\n",
    "        self.W1 = np.random.randn(self.input_layer_size, self.hidden_layer_size) * np.sqrt(2 / self.input_layer_size)\n",
    "        self.W2 = np.random.randn(self.hidden_layer_size, self.output_layer_size) * np.sqrt(2 / self.hidden_layer_size)\n",
    "        # print(f'W1 = {self.W1}')\n",
    "        # print(f'W2 = {self.W2}')\n",
    "\n",
    "        #2. with zeros\n",
    "        # self.W1 = np.zeros((self.input_layer_size, self.hidden_layer_size))\n",
    "        # self.W2 = np.zeros((self.hidden_layer_size, self.output_layer_size))\n",
    "        # print(f'W1 = {self.W1}')\n",
    "        # print(f'W2 = {self.W2}')\n",
    "\n",
    "        #3. specific numbers\n",
    "        # self.W1 = np.array([[0.15, 0.25], [0.20, 0.30]])  # ([[w1, w3], [w2, w4]])\n",
    "        # self.W2 = np.array([[0.40, 0.50], [0.45, 0.55]])\n",
    "        # print(f'W1 = \\n{self.W1}')\n",
    "        # print(f'W2 = \\n{self.W2}')\n",
    "\n",
    "        # bias\n",
    "        self.b1 = 0.35\n",
    "        self.b2 = 0.60\n",
    "\n",
    "    # define the activation function\n",
    "    def activation(self, x):\n",
    "        return (1 / (1 + np.exp(-x)))\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, X):\n",
    "        self.hidden = self.activation(np.dot(X, self.W1) + self.b1)  # H = activation(X*W1 + b)\n",
    "        self.output = self.activation(np.dot(self.hidden, self.W2) + self.b2)  # OP = activation(H*W2 + b)\n",
    "\n",
    "        # print(f'H = {self.hidden}')\n",
    "        # print(f'OP = {self.output}')\n",
    "        return self.output\n",
    "\n",
    "    # back propagation\n",
    "    def back_prop(self, X, y):\n",
    "        output = self.forward(X)\n",
    "        error = np.sum((y - output)**2/2)\n",
    "        delta_output = np.multiply(-(y - output), output * (1 - output))\n",
    "        # print(f'Error = {error}')\n",
    "        self.W2 -= self.lr * (np.dot(self.hidden.T, delta_output)) # W2 = W2 - alpha * (H * ((y-OP) * (OP * (OP - 1))))\n",
    "        # print(f'New W2 Weights: {self.W2}')\n",
    "\n",
    "        delta_hidden = np.dot(delta_output, self.W2.T) * self.hidden * (1 - self.hidden)\n",
    "        self.W1 -= self.lr * np.dot(X.T, delta_hidden)\n",
    "\n",
    "    # training; update the weights for the given number of epoches\n",
    "    def train(self, X, y):\n",
    "        for _ in range(self.number_of_epoches):\n",
    "            self.back_prop(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4ba49-659d-4bd1-8c17-d9b3b0fe43b1",
   "metadata": {},
   "source": [
    "The loss function used here is **Mean Squared Error (MSE)**:\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "The **R² score** measures the proportion of variance explained by the model:\n",
    "$$R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2e422e-d4c8-41b4-bf66-61959cbb3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r_sq(y_true, y_pred):\n",
    "    total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    res = np.sum((y_true - y_pred) ** 2)\n",
    "    return 1 - (res / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4d94ca-8528-4866-a174-b74f819e4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(X, y, k, model, **kwargs):\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    fold = len(X) // k\n",
    "\n",
    "    mse_vals = []\n",
    "    r_sq_vals = []\n",
    "\n",
    "    for i in range(k):\n",
    "        indices_valid = indices[i * fold:(i + 1) * fold]\n",
    "        indices_train = np.concatenate((indices[:i * fold], indices[(i + 1) * fold:]))\n",
    "\n",
    "        X_valid, X_train = X[indices_valid], X[indices_train]\n",
    "        y_valid, y_train = y[indices_valid], y[indices_train]\n",
    "\n",
    "        model_const = model(X_train.shape[1], **kwargs)\n",
    "        model_const.train(X_train, y_train)\n",
    "\n",
    "        y_pred = model_const.predict(X_valid)\n",
    "\n",
    "        mse_vals.append(mse(y_valid, y_pred))\n",
    "        r_sq_vals.append(r_sq(y_valid, y_pred))\n",
    "\n",
    "    y_pred = model_const.predict(X)\n",
    "\n",
    "    return mse_vals[-1], r_sq_vals[-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce935564-0473-49a2-9638-4b74af1b1bfd",
   "metadata": {},
   "source": [
    "\n",
    "### Configurations\n",
    "- **Case (a)**: 3 neurons in hidden layer, learning rate = 0.01\n",
    "- **Case (b)**: 4 neurons in hidden layer, learning rate = 0.001\n",
    "- **Case (c)**: 5 neurons in hidden layer, learning rate = 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff3296f-9b64-4b47-ad0e-0a391a93832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Five Fold Cross Validation: \n",
      "Five fold MSE : 0.025429869727998846, R squared : 0.12335954962034201\n",
      "\n",
      "Results of Ten Fold Cross Validation: \n",
      "Ten fold MSE : 0.024390436801866724, R squared : 0.16095699073990177\n"
     ]
    }
   ],
   "source": [
    "learning_rate = float(input(\"Learning rate: \"))\n",
    "neurons_in = int(input(\"Number of input neurons: \"))\n",
    "neurons_out = int(input(\"Number of output neurons: \"))\n",
    "neurons_hidden = int(input(\"Number of hidden neurons: \"))\n",
    "\n",
    "X = df.iloc[:, :neurons_in].values\n",
    "y = df.iloc[:, -neurons_out:].values\n",
    "\n",
    "# min max normalisation\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "\n",
    "print(\"Results of Five Fold Cross Validation: \")\n",
    "mse_f, r_sq_f = k_fold_validation(X, y, 5, NN, hidden_layer_size=neurons_hidden, output_layer_size=neurons_out, lr=learning_rate, epoches=1000)\n",
    "print(f\"Five fold MSE : {mse_f}, R squared : {r_sq_f}\\n\")\n",
    "\n",
    "print(\"Results of Ten Fold Cross Validation: \")\n",
    "mse_t, r_sq_t = k_fold_validation(X, y, 10, NN, hidden_layer_size=neurons_hidden, output_layer_size=neurons_out, lr=learning_rate, epoches=1000)\n",
    "print(f\"Ten fold MSE : {mse_t}, R squared : {r_sq_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445f421-ecd4-44ae-8e4b-4e996bae171f",
   "metadata": {},
   "source": [
    "## Final Report\n",
    "Input Neurons were fixed at 5, while Output Neurons were fixed at 3. Epochs were 1000.\n",
    "#### Configuration (a): Learning rate: 0.01, Hidden neurons: 3\n",
    "- Five fold MSE : 0.009704866488162727, Five fold R² : 0.725380652661557\n",
    "- Ten fold MSE : 0.007060983316970137, Ten fold R² : 0.8207650474882031\n",
    "\n",
    "#### Configuration (b): Learning rate: 0.001, Hidden neurons: 4\n",
    "- Five fold MSE : 0.02047780502454091, Five fold R² : 0.330307428819119\n",
    "- Ten fold MSE : 0.0205831977379065, Ten fold R²: 0.26219980809154453\n",
    "\n",
    "#### Configuration (c): Learning rate: 0.0001, Hidden neurons: 5\n",
    "- Five fold MSE: 0.025429869727998846, Five fold R²: 0.12335954962034201\n",
    "- Ten fold MSE: 0.024390436801866724, Ten fold R²: 0.16095699073990177"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31b0cc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
